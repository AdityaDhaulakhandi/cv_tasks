{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdityaDhaulakhandi/cv_tasks/blob/main/task1_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97TKcWMAQOEA"
      },
      "outputs": [],
      "source": [
        "from torchvision.io.image import read_image\n",
        "from torchvision.utils import draw_segmentation_masks\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_list =[]\n",
        "for i in range(1,11):\n",
        "  test_list.append(read_image( str(i) + '.jpg'))\n",
        "  # print(test_list[i-1].shape)"
      ],
      "metadata": {
        "id": "i7QFh_d-cSQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V1NW_5mqgb-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pretrained weights for semantic segmentation and generated results on 10 test images(512x512)\n",
        "\n",
        "from torchvision.models.segmentation import deeplabv3_mobilenet_v3_large, DeepLabV3_MobileNet_V3_Large_Weights\n",
        "# from torchvision.models.segmentation import DeepLabV3_ResNet50_Weights,deeplabv3_resnet50\n",
        "# from torchvision.models.segmentation import fcn_resnet50, FCN_ResNet50_Weights\n",
        "# from torchvision.models.segmentation import lraspp_mobilenet_v3_large, LRASPP_MobileNet_V3_Large_Weights"
      ],
      "metadata": {
        "id": "l3QvfNuLbQ2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = DeepLabV3_MobileNet_V3_Large_Weights.DEFAULT\n",
        "model = deeplabv3_mobilenet_v3_large(weights=weights)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "i1QrW-e1cjr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating the inference time for the deep network\n",
        "1. GPU warm-up\n",
        "2. Asynchronous execution"
      ],
      "metadata": {
        "id": "9xjbiOCpmumV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transforms = weights.transforms(resize_size=None)\n",
        "batch = torch.stack( [transforms(img) for img in test_list])"
      ],
      "metadata": {
        "id": "eT6_e_ECczUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transfer all the data and the model to the GPU to remove the transferring time from the cal\n",
        "\n",
        "device = torch.device(\"cuda\")  # selecting the default gpu\n",
        "model.to(device) # moves the model to the cuda device\n",
        "\n",
        "# Creating dummy input for GPU warm-up and moving it to the GPU\n",
        "dummy_input = torch.randn(1, 3,224,224, dtype=torch.float).to(device)\n",
        "\n",
        "# moving the test data to the GPU\n",
        "batch_gpu = batch.to(device)"
      ],
      "metadata": {
        "id": "1brorhLJgNqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True) #to cal timing\n",
        "\n",
        "# Creating an arr to store the timings for no of repeatitions\n",
        "repetitions = 300\n",
        "timings=np.zeros((repetitions,1))\n",
        "\n",
        "#GPU-WARM-UP\n",
        "for _ in range(10):\n",
        "    _ = model(dummy_input)\n",
        "\n",
        "\n",
        "# MEASURE PERFORMANCE on the test data batch\n",
        "with torch.no_grad():\n",
        "    for rep in range(repetitions):\n",
        "        starter.record()\n",
        "        _ = model(batch_gpu)  #run the model on the gpu\n",
        "        ender.record()\n",
        "        # WAIT FOR GPU SYNC\n",
        "        torch.cuda.synchronize()\n",
        "        curr_time = starter.elapsed_time(ender)\n",
        "        timings[rep] = curr_time\n",
        "\n",
        "\n",
        "mean_syn = np.sum(timings) / repetitions\n",
        "std_syn = np.std(timings)\n",
        "print(mean_syn,\" millisec\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZ6vud9Ygu58",
        "outputId": "1c6dab23-c677-4389-c011-59f5e29066f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "85.66366861979166  millisec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "model_inference_time = [85.66366861979166,903.0307497151692, 646.3992173258464 ,43.98113770802816]  # inference time for 10 test images\n",
        "model_inference_time = [x / 10.0 for x in model_inference_time] #for a single test image\n",
        "\n",
        "model_fps = [ math.floor(1000.0/x) for x in model_inference_time ] #to get the frames per sec\n",
        "model_fps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZu-A3vflJ0x",
        "outputId": "0836b953-4024-4580-d2b8-c583608c934e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[116, 11, 15, 227]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "repetitions=100\n",
        "total_time = 0\n",
        "with torch.no_grad():\n",
        "    for rep in range(repetitions):\n",
        "        starter, ender = torch.cuda.Event(enable_timing=True),   torch.cuda.Event(enable_timing=True)\n",
        "        starter.record()\n",
        "        _ = model(batch_gpu)\n",
        "        ender.record()\n",
        "        torch.cuda.synchronize() # wait til the gpu completes\n",
        "        curr_time = starter.elapsed_time(ender)/1000 #convert to second\n",
        "        total_time += curr_time\n",
        "Throughput =   (repetitions*10)/total_time\n",
        "print('Final Throughput:',Throughput)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIsZ-qggVnKL",
        "outputId": "a8a12055-3812-4752-a2fd-de20428d2fc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Throughput: 114.68034474294737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model(batch)[\"out\"]"
      ],
      "metadata": {
        "id": "7mpx5jfCc7V3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pred.shape,pred.min().item(),pred.max().item())\n",
        "# test_img classes H W\n",
        "# print(weights.meta[\"categories\"])"
      ],
      "metadata": {
        "id": "GC6uQeHmqTfo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebbbf959-144c-4c32-8d70-6cb51bc504ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 21, 512, 512]) -8.665416717529297 25.846508026123047\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_masks = pred.softmax(dim=1) #convert the values to [0,1] and interpret them as prob for pixel according to the class\n",
        "# normalized_masks[0][0]"
      ],
      "metadata": {
        "id": "8oDRSJYvfdiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_to_idx = {cls: idx for (idx, cls) in enumerate(weights.meta[\"categories\"])} # create a dictionary for each class\n",
        "# class_to_idx"
      ],
      "metadata": {
        "id": "z68nuYo7Ovvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_dim = 1 # to pick up the max from the column, here col is for each class\n",
        "\n",
        "all_classes_masks = normalized_masks.argmax(class_dim) == torch.arange(normalized_masks.shape[1])[:, None, None, None]\n",
        "# Picks up the max for each class from all the test imgs and compare to the classes in order to create boolean mask\n",
        "all_classes_masks = all_classes_masks.swapaxes(0, 1)\n",
        "# the tensor is for the classes so we swap to make it for each test img"
      ],
      "metadata": {
        "id": "a-LPYCxZR0rL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_with_masks = [\n",
        "    draw_segmentation_masks(img, masks=mask, alpha=0.7)\n",
        "    for img, mask in zip(test_list, all_classes_masks)\n",
        "]"
      ],
      "metadata": {
        "id": "sK74U1MdzyEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in range(10):\n",
        "#   to_pil_image(image_with_masks[i]).show()"
      ],
      "metadata": {
        "id": "XU6jo2_728_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DMRxpU2hX9Op"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}